\documentclass{article}
\usepackage{arxiv}

\usepackage[utf8]{inputenc}
\usepackage[english, russian]{babel}
\usepackage[T2A, T1]{fontenc}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{lipsum}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{doi}
\usepackage{hyperref}



\title{Восстановление функциональных групп головного мозга с помощью графовых диффузных моделей}

\author{
	Касюк Вадим \\
	\texttt{kasiuk.va@phystech.edu} \\
	%% examples of more authors
	\And
	Игнатьев Даниил \\
	\texttt{ignatev.da@phystech.edu} \\
	\And
	Панченко Святослав \\
	\texttt{panchenko.sk@phystech.edu}
	%% \AND
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
	%% \And
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
	%% \And
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
}
\date{}

\renewcommand{\shorttitle}{Ускоренные методы нулевого порядка}
\renewcommand{\undertitle}{}
%%% Add PDF metadata to help others organize their library
%%% Once the PDF is generated, you can check the metadata with
%%% $ pdfinfo template.pdf


\begin{document}
\maketitle

\begin{abstract}
Рассматривается задача классификации активности человека по сигналам электроэнцефалограммы его головного мозга. Классические подходы, основанные на свёрточных сетях, не учитывают пространственную структуру сигнала, регистрируемого датчиками, и неизбежно теряют информацию. Предлагается осуществить классификацию сигналов мозга на основе графовых представлений его функциональных групп, а в качестве предсказательной модели использовать графовую нейронную диффузию GRAND и BLEND. Полученные результаты показывают, что предлагаемое решение превосходит в качестве существующие аналоги.

\end{abstract}


\keywords{Головной мозг, ЭЭГ, нейроные сети, дуффизионые модели}

\section{Введение}

Целью исследования является построение функциональных групп головного мозга с помощью современных графовых диффузионных моделей\cite{wang2019dynamic}. На основании анализа полученных результатов предполагается доказать интерпретируемость ЭЭГ исследований для разных людей, что позволит экспертам в области нейробиологии разрабатывать более эффективные методы лечения патологий головного мозга\cite{kober2008functional}.

Обьектом исследования являются простраственные временные ряды полученные с помощью ЭЭГ головного мозга группы испытуемых. Устройство для считывания сигнала представляет собой
набор датчиков – электродов, расположенных на поверхности кожи головы по одной
из общепринятых систем размещения. На выходе получается меняющая во времени с определенной частотой дискретизации матрица с значениями интенсивности датчиков в ее ячейках.

Проблематика данной задачи заключается в том, что предыдущие исследования \cite{gcnsnet2020, Hou_2020, LI2023833} не учитывают пространственную структуру сигнала, что не позволяет добиться высокой точности. Более того, даже те модели\cite{gcnsnet2020, chamberlain2021blend, varenik2022}, которые пытаются учесть эту особенность, не учитывают динамическую зависимость этих групп, что так же ограничивает точность результатов.

Автор статьи ставит перед собой задачи : 1) Повторить эскперименты \href{https://github.com/intsystems/PanchenkoPhD2022}{Святослава Панченко}
2) Провести эксперимент используя графовую нейронную диффузию GRAND\cite{DBLP:journals/corr/abs-2106-10934} и
BLEND\cite{DBLP:journals/corr/abs-2110-09443}.
3) Провести сранительный анализ с предыдущими решениями

\section{Постановка задачи}
Дана выборка $\mathcal{D} = (\underline{\mathbf{X}}, \mathbf{Z}, \mathbf{y})$ активности головного мозга, где
\[ \underline{\mathbf{X}} =[︀\mathbf{X}_m]︀_{m=1}^M \textrm{ -- набор сигналов,}\]
\[\mathbf{X}_m=[\mathbf{x}_t]_{t\in T}  \textrm{ -- сигнал, полученный в } m\textrm{-ом испытании,}\]
\[\mathbf{x}_t \in \mathbb{R}^E \textrm{ -- наблюдения сигнала в момент времени }t, \]
\[\mathbf{Z} = [\mathbf{z}_k]_{k=1}^E
z_k \in \mathbf{R}^3 \textrm{ -- координаты электродов},\]
\[\mathbf{y} = [y_m]_{m=1}^M \textrm{ -- целевая переменная,}\]
\[y_m \in {1,... C} \textrm{ -- метка класса},\]
\[T = \{t_n\}_{n=1}^N \textrm{ -- набор временных отсчетов},\]
\[E = 62 \textrm{ -- число электродов,}\]
\[N \textrm{ -- число наблюдений в одном отрезке сигнала.}\]
По выборке $\mathcal{D}$ строится неориентированный динамический граф:
$\mathcal{G}(m, t) = \Big(\mathcal{V}(m, t), \mathcal{E}(m, t), \vect \mathbf{A}_{\underline{\vect \mathbf{X}},\vect \mathbf{Z}}(m, t)\Big),$
где
$$
\mathcal{V}(m, t) \textrm{ -- множество электродов,}
$$
$$
\mathcal{E}(m, t) \textrm{ -- множество ребер,}
$$
$$\vect \mathbf{A}_{\underline{\vect \mathbf{X}},\vect \mathbf{Z}}(m, t) \textrm{ -- матрица смежности графа, определяющая веса ребер },$$
$$
\underline{\mathbf{A}}_{\underline{\vect \mathbf{X}},\vect \mathbf{Z}} = [\mathbf{A}_{\underline{\vect \mathbf{X}},\vect \mathbf{Z}}]_{m=1}^M \textrm{ -- набор матриц смежности.}
$$
Для решения задачи декодирования рассматривается модель из класса графовых рекуррентных нейронный сетей, параметризуемого множеством $\Theta$:
\[h_{\bm{\theta}} : (\underline{\mathbf{X}}, \underline{\mathbf{A}}_{\underline{\mathbf{X}},\mathbf{Z}}) \rightarrow y, \bm{\theta}\in\Theta\]

В качестве функции ошибки выбрана кросс–энтропия:
\[\mathcal{L} = - \frac{1}{M} \sum\limits_{m=1}^M\bigg[\sum\limits_{c=1}^C\mathbbm{1}(y_m=c)\log(p_m^c)\bigg],\] 
где
\[ p_m^c = h_{\mathbf{\theta}}\bigg(\mathbf{X}_m, \underline{\mathbf{A}}_{\underline{\mathbf{X}},\mathbf{Z}}(m)\bigg) \textrm{-- вероятность класса } c\]
\[\textrm{для } \mathbf{X}_m \textrm{ с матрицей } \underline{\mathbf{A}}_{\underline{\mathbf{X}},\mathbf{Z}}(m).\]
Задача поиска оптимальных параметров имеет следующий вид:
\[\hat\mathbf{\theta} = \arg\max_{\bm{\theta}\in\Theta} \mathcal{L}(\bm{\theta}, \mathbf{X}, \underline{\mathbf{A}}_{\underline{\mathbf{X}},\mathbf{Z}})\]

\section{Предложенное решение}
Предлагается следующий пайплайн GNN+LSTM:
\begin{enumerate}
    \item По исходным данным $\mathcal{D}$ строится неориентированный динамический граф $\mathcal{G}(m, t)$.
    \item Граф $\mathcal{G}(m, t)$ подается на вход GNN. На выходе получаем многомерный временной ряд представлений исходных данных.
    \item На выходах GNN запускаем LSTM, по его скрытому состоянию после обработки входа производим классификацию
\end{enumerate}
Для построения матрицы смежности графа будем использовать методы, исследованные в \cite{varenik2022}. Лучшие результаты были получены методом на основе корреляции Пирсона двух сигналов, поэтому будем использовать именно его. Также важным гиперпараметром является размер окна входных данных, по которому будем строить граф.
\par
В качестве GNN предлагается использовать графовую диффузию GRAND. В основе алгоритма лежит связь с физическим уравнением диффузии:
$$
\frac{\partial x(u,t)}{\partial t} = \text{div}[g(u, t, x(u,t))\nabla_u x],
$$
где $x(u,t)$ -- величина потока (тепла) в среде в точке пространства $u$ в момент времени $t$. \\Схожим образом определяется диффузия на графе. Пусть $\mathcal{G} = (\mathcal{V}=\{1,...,n\},\mathcal{E})$ неориентированный граф с множествами вершин и ребер $\mathcal{V}$ и $\mathcal{E}$ соответственно. Обозначим через $\mathbf{z}_i(t) = (\mathbf{u}_i, \mathbf{x}_i)\in\mathbb{R}^d\times\mathbb{R}^{d'}$ объедиененные координаты $i$-ой вершины. Тогда уравнение диффузии на графе имеет вид:
$$ \frac{\partial{\mathbf{z}_i(t)}}{\partial{t}} = div [a(\mathbf{z}(t))\nabla \mathbf{z}_i(t)],
$$
где $a(\mathbf{z}(t))$ -- диффузивность, определяет интенсивность процесса вдоль различных направлений. Найдем решение уравнения, переписав правую часть равенства, используя определения операторов дивергенции и градиента на графе и проведя дискретизацию дифференциального уравнения:
$$
    \frac{z^{(k+1)}_i - z^{(k)}_i}{\tau} = \sum\limits_{j:(i,j)\in\mathcal{E}(U^{(k)})}a(z^{(k)}_i, z^{(k)}_j)(z^{(k)}_j - z^{(k)}_i) 
$$
При $\tau = 1$ уравнение компактно переписывается в виде явной схемы Эйлера:

$$ Z^{(k+1)} = (A^{(k)} - I)Z^{(k)} = Q^{(k)}Z^{(k)}$$
Решение вычисляется последовательным применением схемы несколько раз подряд. Схема GRAND обобщает многие другие подходы, в том числе может воспроизводить GCN \cite{chamberlain2021blend}, при этом использует меньше параметров, чем GCN.

\section{Вычислительный эксперимент}
Нами ставятся две гипотезы:
\begin{enumerate}
    \item Утилизация пространственной информации позволит GNN показать результат лучше, чем GNN при решении задачи классификации.
    \item Модель GRAND будет более робастной, чем GCN за счет меньшего количества параметров при том же качестве.
\end{enumerate}
Целью эксперимента является проверить эти гипотезы. \\
Датасет для экспериментов: EEG Database to examine EEG correlates of genetic
predisposition to alcoholism -- данные ЭЭГ испытуемых из двух групп: страдающих алкоголизмом и не страдающих. \href{https://archive.ics.uci.edu/dataset/121/eeg+database}{Ссылка на датасет}
\\
В ходе эксперимента были обучены модели GCN для нескольких размеров окна.
\newpage
\begin{flushleft}
Кривые обучения и значения метрик на тесте для GCN.
\end{flushleft}
\begin{figure}[!h]
\begin{minipage}{.475\textwidth} 
    \includegraphics[width=\textwidth]{t5(1).png}
 	\caption{Кривые обучения}
\end{minipage}
\begin{minipage}{.475\textwidth}
    \includegraphics[width=\textwidth]{final_res(1).png}
 	\caption{Значения метрик}
\end{minipage}
\end{figure}

\section{Заключение}
В дальнейшем планируется довести эксперимент до конца и проверить поставленные гипотезы.


\bibliographystyle{unsrt}
\bibliography{references}
\end{document}
